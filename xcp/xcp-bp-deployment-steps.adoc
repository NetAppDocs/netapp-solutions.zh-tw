---
sidebar: sidebar 
permalink: xcp/xcp-bp-deployment-steps.html 
keywords: deployment, solution components, linux server, windows server aff a800, ha 
summary: 本節涵蓋NetApp XCP資料傳輸的部署步驟。 
---
= 部署步驟
:hardbreaks:
:allow-uri-read: 
:nofooter: 
:icons: font
:linkattrs: 
:imagesdir: ./../media/


link:xcp-bp-file-analytics.html["上一篇：檔案分析。"]



== 測試病床詳細資料

下表提供用於此部署和效能驗證的測試台詳細資料。

|===
| 解決方案元件 | 詳細資料 


| XCP 1.7版  a| 
* 一部Linux伺服器- Linux（RHEL 7.9或RHEL 8）
* 一台Windows伺服器–Windows Server 2019標準




| 適用於AFF 來源Volume的NetApp解決方案：儲存陣列HA配對  a| 
* AFF8080
* NetApp ONTAP 產品9.
* NFS傳輸協定




| 適用於目的地Volume的NetApp AFF 解決方案儲存陣列HA配對  a| 
* 解答800 AFF
* 功能9. ONTAP
* NFS傳輸協定




| Fujitsu PRIMERGY RX2540伺服器 | 每個配備：* 48個CPU * Intel Xeon * 256GB實體記憶體* 10GbE雙埠 


| 網路 | 10GbE 
|===


== 部署步驟- NAS

若要部署NetApp XCP以進行資料傳輸、請先在目的地位置安裝並啟動XCP軟體。您可以檢閱中的詳細資料 https://["NetApp XCP使用者指南"^]。若要這麼做、請完成下列步驟：

. 符合一節中詳述的先決條件 link:xcp-bp-netapp-xcp-overview.html#prerequisites-for-xcp["「XCP的先決條件」。"]
. 從下載XCP軟體 https://["NetApp XCP（下載）頁面"^]。
. 將下載的XCP tar檔案複製到XCP伺服器。
+
....
# scp Documents/OneDrive\ -\ NetApp\ Inc/XCP/software/1.6.1/NETAPP_XCP_1.6.1.tgz mailto:root@10.63.150.53:/usr/src
....
. 解壓縮tar檔案。
+
....
[root@mastr-53 src]# tar -zxvf NETAPP_XCP_1.6.1.tgz
....
. 請從下載授權 https://["https://xcp.netapp.com/license/xcp.xwic"^] 並複製到XCP伺服器。
. 啟動授權。
+
....
[root@mastr-53 linux]# ./xcp activate
[root@mastr-53 src]# cp license /opt/NetApp/xFiles/xcp/license
[root@mastr-53 src]# cd /usr/src/xcp/linux/
[root@mastr-53 linux]# ./xcp activate
....
. 尋找來源NFS連接埠和目的地NFS伺服器。預設連接埠為2049。
+
....
[root@mastr-53 ~]# rpcinfo -p 10.63.150.213
[root@mastr-53 ~]# rpcinfo -p 10.63.150.63
....
. 檢查NFS連線。使用到NFS伺服器連接埠的telnet檢查NFS伺服器（無論是來源伺服器或目的地）。
+
....
[root@mastr-53 ~]# telnet 10.63.150.127 2049
[root@mastr-53 ~]# telnet 10.63.150.63 2049
....
. 設定目錄。
+
.. 建立NFS Volume並匯出XCP目錄的NFS。您也可以利用作業系統的NFS匯出功能來進行XCP目錄。
+
....
A800-Node1-2::> volume create -vserver Hadoop_SVM -volume xcpcatalog -aggregate aggr_Hadoop_1 -size 50GB -state online -junction-path /xcpcatalog -policy default -unix-permissions ---rwxr-xr-x -type RW -snapshot-policy default -foreground true
A800-Node1-2::> volume mount -vserver Hadoop_SVM -volume xcpcatalog_vol -junction-path /xcpcatalog
....
.. 檢查NFS匯出。
+
....
[root@mastr-53 ~]# showmount -e 10.63.150.63 | grep xcpca
/xcpcatalog (everyone)
....
.. 更新：xcp.ini`。
+
....
[root@mastr-53 ~]# cat /opt/NetApp/xFiles/xcp/xcp.ini
# Sample xcp config
[xcp]
catalog = 10.63.150.64:/xcpcatalog

[root@mastr-53 ~]#
....


. 使用「XCP show」尋找來源NAS匯出。尋找：
+
....
== NFS Exports ==
== Attributes of NFS Exports ==
....
+
....
[root@mastr-53 linux]# ./xcp show 10.63.150.127
== NFS Exports ==
<check here>
== Attributes of NFS Exports ==
<check here>
....
. （選用）掃描來源NAS資料。
+
....
[root@mastr-53 linux]# ./xcp scan -newid xcpscantest4 -stats 10.63.150.127:/xcpsrc_vol
....
+
掃描來源NAS資料有助於瞭解資料配置、並找出任何可能的移轉問題。XCP掃描作業時間與檔案數量和目錄深度成比例。如果您熟悉NAS資料、可以跳過此步驟。

. 檢查由「XCP掃描」建立的報告。主要搜尋無法讀取的資料夾和無法讀取的檔案。
+
....
[root@mastr-53 linux]# mount 10.63.150.64:/xcpcatalog  /xcpcatalog
base) nkarthik-mac-0:~ karthikeyannagalingam$ scp -r root@10.63.150.53:/xcpcatalog/catalog/indexes/xcpscantest4 Documents/OneDrive\ -\ NetApp\ Inc/XCP/customers/reports/
....
. （選用）變更inode。檢視inode數量、並根據要移轉或複製的檔案數量、修改目錄和目的地磁碟區的數量（如有需要）。
+
....
A800-Node1-2::> volume show -volume xcpcatalog -fields files,files-used
A800-Node1-2::> volume show -volume xcpdest -fields files,files-used
A800-Node1-2::> volume modify -volume xcpcatalog -vserver A800-Node1_vs1 -files 2000000
Volume modify successful on volume xcpcatalog of Vserver A800-Node1_vs1.

A800-Node1-2::> volume show -volume xcpcatalog -fields files,files-used
....
. 掃描目的地Volume。
+
....
[root@mastr-53 linux]# ./xcp scan -stats 10.63.150.63:/xcpdest
....
. 檢查來源與目的地磁碟區空間。
+
....
[root@mastr-53 ~]# df -h /xcpsrc_vol
[root@mastr-53 ~]# df -h /xcpdest/
....
. 使用「XCP COPY」將資料從來源複製到目的地、然後檢查摘要。
+
....
[root@mastr-53 linux]# ./xcp copy -newid create_Sep091599198212 10.63.150.127:/xcpsrc_vol 10.63.150.63:/xcpdest
<command inprogress results removed>
Xcp command : xcp copy -newid create_Sep091599198212 -parallel 23 10.63.150.127:/xcpsrc_vol 10.63.150.63:/xcpdest
Stats       : 9.07M scanned, 9.07M copied, 118 linked, 9.07M indexed, 173 giants
Speed       : 1.57 TiB in (412 MiB/s), 1.50 TiB out (392 MiB/s)
Total Time  : 1h6m.
STATUS      : PASSED
[root@mastr-53 linux]#
....
+

NOTE: 根據預設、XCP會建立七個平行處理程序來複製資料。這是可以調整的。

+

NOTE: NetApp建議將來源Volume設定為唯讀。即時而言、來源Volume是即時且作用中的檔案系統。「XCP複製」作業可能會失敗、因為NetApp XCP不支援應用程式持續變更的即時來源。

+
對於Linux、XCP需要索引ID、因為XCP Linux會執行目錄分類。

. （可選）檢查目標NetApp捲上的inode。
+
....
A800-Node1-2::> volume show -volume xcpdest -fields files,files-used
vserver        volume  files    files-used
-------------- ------- -------- ----------
A800-Node1_vs1 xcpdest 21251126 15039685

A800-Node1-2::>
....
. 使用「XCP同步」執行遞增更新。
+
....
[root@mastr-53 linux]# ./xcp sync -id create_Sep091599198212
Xcp command : xcp sync -id create_Sep091599198212
Stats       : 9.07M reviewed, 9.07M checked at source, no changes, 9.07M reindexed
Speed       : 1.73 GiB in (8.40 MiB/s), 1.98 GiB out (9.59 MiB/s)
Total Time  : 3m31s.
STATUS      : PASSED
....
+
對於本文來說、為了模擬即時、來源資料中的一百萬個檔案已重新命名、然後使用「XCP同步」將更新的檔案複製到目的地。對於Windows、XCP需要來源和目的地路徑。

. 驗證資料傳輸。您可以使用「XCP驗證」來驗證來源和目的地是否擁有相同的資料。
+
....
Xcp command : xcp verify 10.63.150.127:/xcpsrc_vol 10.63.150.63:/xcpdest
Stats       : 9.07M scanned, 9.07M indexed, 173 giants, 100% found (6.01M have data), 6.01M compared, 100% verified (data, attrs, mods)
Speed       : 3.13 TiB in (509 MiB/s), 11.1 GiB out (1.76 MiB/s)
Total Time  : 1h47m.
STATUS      : PASSED
....


XCP文件針對「shcan」、「copy」、「Sync」和「驗證」作業提供多種選項（例如）。如需詳細資訊、請參閱 https://["NetApp XCP使用者指南"^]。


NOTE: Windows客戶應該使用存取控制清單（ACL）來複製資料。NetApp建議使用命令「XCP copy -ACL -fallbackuser\<使用者名稱>-fallbackGroup\<使用者名稱或群組名稱><來源><目的地>」。為了發揮最大效能、考慮到來源磁碟區具有含ACL的SMB資料、以及NFS和SMB可存取的資料、目標必須是NTFS磁碟區。使用XCP（NFS版本）、從Linux伺服器複製資料、然後從Windows伺服器執行XCP（SMB版本）同步、使用「-ACL」和「-nocdata」選項、將ACL從來源資料複製到目標SMB資料。

如需詳細步驟、請參閱 https://["設定「管理稽核與安全性記錄」原則"^]。



== 部署步驟- HDFS/MapRFS資料移轉

在本節中、我們將討論稱為Hadoop Filesystem Data Transfer to NAS的新XCP功能、此功能可將資料從HDFS/MapRFS移轉至NFS、反之亦然。



=== 先決條件

對於MapRFS/HDFS功能、您必須在非root使用者環境中執行下列程序。通常、非root使用者是HDFS、MapR、或是有權變更HDFS和MapRFS檔案系統的使用者。

. 在CLI或使用者的.bashrc檔案中設定CLASSPATH、Hadoop主目錄、NHDFs_libjvm_path、LB_LIB_LIBHDFs_path變數、以及「XCP」命令。
+
** NHDFs_LIBHDFs_path指向libhdfs.so檔案。此檔案提供HDFS API、可將HDFS/MapRFS檔案和檔案系統做為Hadoop發佈的一部分進行互動和操作。
** NHDFS_libjvm_path指向libjvm.so檔案。這是位於JRE位置的共享Java虛擬機器程式庫。
** 類路徑使用（Hadoop classpaths–globb）值指向所有Jar檔案。
** LD_LIBRARY_路徑 指向Hadoop原生程式庫資料夾位置。
+
請參閱下列以Cloudera叢集為基礎的範例。

+
[listing]
----
export CLASSPATH=$(hadoop classpath --glob)
export LD_LIBRARY_PATH=/usr/java/jdk1.8.0_181-cloudera/jre/lib/amd64/server/
export HADOOP_HOME=/opt/cloudera/parcels/CDH-6.3.4-1.cdh6.3.4.p0.6751098/
#export HADOOP_HOME=/opt/cloudera/parcels/CDH/
export NHDFS_LIBJVM_PATH=/usr/java/jdk1.8.0_181-cloudera/jre/lib/amd64/server/libjvm.so
export NHDFS_LIBHDFS_PATH=$HADOOP_HOME/lib64/libhdfs.so
----
+
在此版本中、我們支援XCP掃描、複製及驗證從HDFS移轉至NFS的作業和資料移轉。您可以從資料湖叢集的單一工作節點和多個工作節點傳輸資料。在1.8版中、root和非root使用者可以執行資料移轉。







=== 部署步驟-非root使用者將HDFS/MaprFS資料移轉至NetApp NFS

. 請依照「部署步驟」一節中的步驟1至9中所述的相同步驟進行。
. 在下列範例中、使用者會將資料從HDFS移轉至NFS。
+
.. 在HDFS中建立資料夾和檔案（使用「Hadoop FS -copyFromLocal」）。
+
[listing]
----
[root@n138 ~]# su - tester -c 'hadoop fs -mkdir /tmp/testerfolder_src/util-linux-2.23.2/mohankarthikhdfs_src'
[root@n138 ~]# su - tester -c 'hadoop fs -ls -d  /tmp/testerfolder_src/util-linux-2.23.2/mohankarthikhdfs_src'
drwxr-xr-x   - tester supergroup          0 2021-11-16 16:52 /tmp/testerfolder_src/util-linux-2.23.2/mohankarthikhdfs_src
[root@n138 ~]# su - tester -c "echo 'testfile hdfs' > /tmp/a_hdfs.txt"
[root@n138 ~]# su - tester -c "echo 'testfile hdfs 2' > /tmp/b_hdfs.txt"
[root@n138 ~]# ls -ltrah /tmp/*_hdfs.txt
-rw-rw-r-- 1 tester tester 14 Nov 16 17:00 /tmp/a_hdfs.txt
-rw-rw-r-- 1 tester tester 16 Nov 16 17:00 /tmp/b_hdfs.txt
[root@n138 ~]# su - tester -c 'hadoop fs -copyFromLocal /tmp/*_hdfs.txt hdfs:///tmp/testerfolder_src/util-linux-2.23.2/mohankarthikhdfs_src'
[root@n138 ~]#
----
.. 檢查HDFS資料夾中的權限。
+
[listing]
----
[root@n138 ~]# su - tester -c 'hadoop fs -ls hdfs:///tmp/testerfolder_src/util-linux-2.23.2/mohankarthikhdfs_src'
Found 2 items
-rw-r--r--   3 tester supergroup         14 2021-11-16 17:01 hdfs:///tmp/testerfolder_src/util-linux-2.23.2/mohankarthikhdfs_src/a_hdfs.txt
-rw-r--r--   3 tester supergroup         16 2021-11-16 17:01 hdfs:///tmp/testerfolder_src/util-linux-2.23.2/mohankarthikhdfs_src/b_hdfs.txt
----
.. 在NFS中建立資料夾並檢查權限。
+
[listing]
----
[root@n138 ~]# su - tester -c 'mkdir /xcpsrc_vol/mohankarthiknfs_dest'
[root@n138 ~]# su - tester -c 'ls -l /xcpsrc_vol/mohankarthiknfs_dest'
total 0
[root@n138 ~]# su - tester -c 'ls -d /xcpsrc_vol/mohankarthiknfs_dest'
/xcpsrc_vol/mohankarthiknfs_dest
[root@n138 ~]# su - tester -c 'ls -ld /xcpsrc_vol/mohankarthiknfs_dest'
drwxrwxr-x 2 tester tester 4096 Nov 16 14:32 /xcpsrc_vol/mohankarthiknfs_dest
[root@n138 ~]#
----
.. 使用XCP將檔案從HDFS複製到NFS、然後檢查權限。
+
[listing]
----
[root@n138 ~]# su - tester -c '/usr/src/hdfs_nightly/xcp/linux/xcp copy -chown hdfs:///tmp/testerfolder_src/util-linux-2.23.2/mohankarthikhdfs_src/ 10.63.150.126:/xcpsrc_vol/mohankarthiknfs_dest'
XCP Nightly_dev; (c) 2021 NetApp, Inc.; Licensed to Karthikeyan Nagalingam [NetApp Inc] until Wed Feb  9 13:38:12 2022

xcp: WARNING: No index name has been specified, creating one with name: autoname_copy_2021-11-16_17.04.03.652673

Xcp command : xcp copy -chown hdfs:///tmp/testerfolder_src/util-linux-2.23.2/mohankarthikhdfs_src/ 10.63.150.126:/xcpsrc_vol/mohankarthiknfs_dest
Stats       : 3 scanned, 2 copied, 3 indexed
Speed       : 3.44 KiB in (650/s), 80.2 KiB out (14.8 KiB/s)
Total Time  : 5s.
STATUS      : PASSED
[root@n138 ~]# su - tester -c 'ls -l /xcpsrc_vol/mohankarthiknfs_dest'
total 0
-rw-r--r-- 1 tester supergroup 14 Nov 16 17:01 a_hdfs.txt
-rw-r--r-- 1 tester supergroup 16 Nov 16 17:01 b_hdfs.txt
[root@n138 ~]# su - tester -c 'ls -ld /xcpsrc_vol/mohankarthiknfs_dest'
drwxr-xr-x 2 tester supergroup 4096 Nov 16 17:01 /xcpsrc_vol/mohankarthiknfs_dest
[root@n138 ~]#
----




link:xcp-bp-sizing-guidelines-overview.html["下一步：規模調整準則。"]
