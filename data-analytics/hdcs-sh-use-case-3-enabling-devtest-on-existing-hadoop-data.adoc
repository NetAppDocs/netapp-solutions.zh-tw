---
sidebar: sidebar 
permalink: data-analytics/hdcs-sh-use-case-3-enabling-devtest-on-existing-hadoop-data.html 
keywords: devtest, hadoop, spark, analytics data, reporting 
summary: 在此使用案例中、客戶的需求是根據現有的Hadoop叢集、快速且有效率地建置新的Hadoop / Spark叢集、其中包含大量用於DevTest的分析資料、並在同一個資料中心和遠端位置進行報告。 
---
= 使用案例3：在現有Hadoop資料上啟用DevTest
:hardbreaks:
:allow-uri-read: 
:nofooter: 
:icons: font
:linkattrs: 
:imagesdir: ./../media/


[role="lead"]
在此使用案例中、客戶的需求是根據現有的Hadoop叢集、快速且有效率地建置新的Hadoop / Spark叢集、其中包含大量用於DevTest的分析資料、並在同一個資料中心和遠端位置進行報告。



== 案例

在此案例中、多個Spark / Hadoop叢集是以內部部署的大型Hadoop資料湖實作以及災難恢復位置所建置而成。



== 需求與挑戰

此使用案例的主要要求與挑戰包括：

* 針對DevTest、QA或任何其他需要存取相同正式作業資料的目的、建立多個Hadoop叢集。這方面的挑戰是、以極具空間效益的方式、即時複製大型Hadoop叢集多次。
* 將Hadoop資料同步至DevTest和報告團隊、以提高營運效率。
* 在正式作業和新叢集之間使用相同的認證資料來散佈Hadoop資料。
* 使用排程的原則來有效率地建立QA叢集、而不會影響正式作業叢集。




== 解決方案

FlexClone技術可用來滿足上述需求。FlexClone技術是Snapshot複本的讀寫複本。它會從父Snapshot複本資料讀取資料、只會消耗新增/修改區塊的額外空間。它既快速又節省空間。

首先、使用NetApp一致性群組建立現有叢集的Snapshot複本。

NetApp System Manager或儲存設備管理提示中的Snapshot複本。一致性群組Snapshot複本是應用程式一致的群組Snapshot複本、而FlexClone Volume則是根據一致性群組Snapshot複本建立。值得一提的是、FlexClone Volume繼承父Volume的NFS匯出原則。建立Snapshot複本之後、必須安裝新的Hadoop叢集以供DevTest和報告之用、如下圖所示。從新 Hadoop 叢集複製的 NFS Volume 可存取 NFS 資料。

此影像顯示DevTest的Hadoop叢集。

image::hdcs-sh-image11.png[hdcs sh image11.]
