---
sidebar: sidebar 
permalink: ai/osrunai_submitting_jobs_in_run_ai_cli.html 
keywords:  
summary:  
---
= 在Run:AI CLI中提交工作
:hardbreaks:
:allow-uri-read: 
:nofooter: 
:icons: font
:linkattrs: 
:imagesdir: ./../media/


[role="lead"]
本節提供基本Run:AI命令的詳細資訊、可用於執行任何Kubernetes工作。它根據工作負載類型分為三個部分。AI / ML / DL工作負載可分為兩種一般類型：

* *無人蔘與的訓練課程*。有了這些類型的工作負載、資料科學家就能準備好自行執行的工作負載、然後將其傳送執行。執行期間、客戶可以檢查結果。這類工作負載通常用於正式作業、或是在不需要人為介入的階段進行模型開發。
* *互動式建置工作階段*。有了這些類型的工作負載、資料科學家就能開啟與Bash、Jupyter Notebook、遠端PyCharm或類似的IDE互動式工作階段、並直接存取GPU資源。我們在第三個案例中、使用連接埠執行互動式工作負載、以向容器使用者展示內部連接埠。




== 無人管理的訓練工作負載

設定專案並分配GPU之後、您可以在命令列使用下列命令來執行任何Kubernetes工作負載：

....
$ runai project set team-a runai submit hyper1 -i gcr.io/run-ai-demo/quickstart -g 1
....
此命令會為團隊A開始無人值守的訓練工作、並分配單一GPU。工作是以「GCR.IO/RUN -AI DEMO / quickstart」樣本泊塢視窗影像為基礎。我們將工作命名為「hyper1」。然後您可以執行下列命令來監控工作的進度：

....
$ runai list
....
下圖顯示「Runai list」命令的結果。您可能會看到下列一般狀態：

* 「ContainerCreating」。Docker容器正在從雲端儲存庫下載。
* 「待處理」。工作正在等待排程。
* 《執行中》。工作正在執行中。


image:osrunai_image5.png["錯誤：缺少圖形影像"]

若要取得工作的其他狀態、請執行下列命令：

....
$ runai get hyper1
....
若要檢視工作記錄、請執行「Runai logs <job-name>」命令：

....
$ runai logs hyper1
....
在此範例中、您應該會看到正在執行的DL工作階段記錄、包括目前的訓練時期、ETA、Loss Function Value、Accuracy、以及每個步驟所經過的時間。

您可以在的Run:AI UI上檢視叢集狀態 https://app.run.ai/["https://app.run.ai/"^]。在「儀表板」>「總覽」下、您可以監控GPU使用率。

若要停止此工作負載、請執行下列命令：

....
$ runai delte hyper1
....
此命令可停止訓練工作負載。您可以再次執行「Runai list」（Runai清單）來驗證此動作。如需詳細資訊、請參閱 https://docs.run.ai/Researcher/Walkthroughs/Walkthrough-Launch-Unattended-Training-Workloads-/["啟動無人管理的訓練工作負載"^]。



== 互動式建置工作負載

設定專案並分配GPU之後、您可以在命令列使用下列命令來執行互動式建置工作負載：

....
$ runai submit build1 -i python -g 1 --interactive --command sleep --args infinity
....
工作是以範例Docker影像python為基礎。我們將工作建置命名為「1」。


NOTE: 「互動」旗標表示工作沒有開始或結束研究人員有責任完成這項工作。系統管理員可以定義互動工作的時間限制、之後系統會終止這些工作。

「-g 1」旗標會將單一GPU配置給此工作。提供的命令與引數是「-command sleep- args infinity」。您必須提供命令、否則容器會立即啟動並結束。

下列命令的運作方式與中所述的命令類似 <<無人管理的訓練工作負載>>：

* 「Runai list」：顯示名稱、狀態、年齡、節點、映像、 專案、使用者及GPU的工作。
* 「Runai Get build1」：在工作建置1上顯示其他狀態。
* "Runai DELETE build1"：停止互動式工作負載建置1。若要將Bash Shell移至容器、請執行下列命令：


....
$ runai bash build1
....
這可直接在電腦中提供Shell。然後、資料科學家可以在容器內開發或微調模型。

您可以在的Run:AI UI上檢視叢集狀態 https://app.run.ai["https://app.run.ai"^]。如需詳細資訊、請參閱 https://docs.run.ai/Researcher/Walkthroughs/Walkthrough-Start-and-Use-Interactive-Build-Workloads-/["啟動及使用互動式建置工作負載"^]。



== 互動式工作負載與連接的連接埠

作為互動式建置工作負載的延伸、您可以在使用Run:AI CLI啟動容器時、向容器使用者顯示內部連接埠。這對於雲端環境、使用Jupyter筆記型電腦或連線至其他微服務都很有用。 https://kubernetes.io/docs/concepts/services-networking/ingress/["入侵"^] 允許從Kubernetes叢集外部存取Kubernetes服務。您可以建立規則集合來定義哪些傳入連線可到達哪些服務、藉此設定存取。

為了更妥善管理叢集中的外部服務存取、建議叢集管理員安裝 https://kubernetes.io/docs/concepts/services-networking/ingress/["入侵"^] 並設定負載平衡器。

若要使用Ingress做為服務類型、請執行下列命令、在提交工作負載時設定方法類型和連接埠：

....
$ runai submit test-ingress -i jupyter/base-notebook -g 1 \
  --interactive --service-type=ingress --port 8888 \
  --args="--NotebookApp.base_url=test-ingress" --command=start-notebook.sh
....
容器成功啟動後、執行「Runai list」（執行清單）以查看用來存取Jupyter Notebook的「服務URL（S）」。URL由入口端點、工作名稱和連接埠組成。例如、請參閱 https://10.255.174.13/test-ingress-8888[]。

如需詳細資料、請參閱 https://docs.run.ai/Researcher/Walkthroughs/Walkthrough-Launch-an-Interactive-Build-Workload-with-Connected-Ports/["使用連接的連接埠啟動互動式建置工作負載"^]。
