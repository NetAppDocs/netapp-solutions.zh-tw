---
sidebar: sidebar 
permalink: ai/aipod_nv_architecture.html 
keywords: NetApp AI, AI, Artificial Intelligence, ML, Machine Learning, NVIDIA, NVIDIA AI Enterprise, NVIDIA BasePOD, NVIDIA DGX 
summary: 採用 NVIDIA DGX 系統的 NetApp AI Pod - 架構 
---
= 採用 NVIDIA DGX 系統的 NetApp AI Pod - 架構
:hardbreaks:
:allow-uri-read: 
:nofooter: 
:icons: font
:linkattrs: 
:imagesdir: ./../media/


link:aipod_nv_sw_components.html["上一篇： ONTAP AI - 軟體元件。"]

此參考架構運用不同的架構來進行運算叢集互連和儲存存取、並提供運算節點之間的 NDR200 和 HDR200 Infiniband （ IB ）連線選項。DGX H100 系統隨附預先安裝的 ConnectX-7 卡、可用於 NDR IB 連線、而 DGX A100 系統則可分別使用 ConnectX-6 或 ConnectX-7 卡進行 HDR 或 NDR 連線。



== ONTAP AI 搭配 DGX H100 系統

下圖顯示搭配 ONTAP AI 使用 DGX H100 系統時的整體解決方案拓撲。

image:oai_H100_topo.png["錯誤：缺少圖形影像"]

在此組態中、運算叢集網路使用一對 QM9700 NDR IB 交換器、這些交換器會連接在一起以獲得高可用度。每個 DGX H100 系統都使用八個 NDR200 連線連接至交換器、並將偶數連接埠連接至一台交換器、而奇數連接埠則連接至另一台交換器。

對於儲存系統存取、頻內管理和用戶端存取、會使用一對 SN4600 乙太網路交換器。交換器是透過交換器間的連結連接、並設定多個 VLAN 來隔離各種流量類型。對於較大型的部署、乙太網路可擴充至葉脊組態、視需要新增額外的交換器配對以供脊椎和其他葉片使用。每個 DGX A100 系統均配備兩個雙埠 ConnectX-6 卡、用於乙太網路和儲存流量、而此解決方案則有四個連接埠、連接至以 200 Gbps 速度連接至 SN4600 乙太網路交換器。每個卡的一個連接埠都設定為 LACP MLAG 連結、每個交換器連接一個連接埠、而用於頻內管理、用戶端存取和使用者層級儲存存取的 VLAN 則裝載在此連結上。每個卡上的另一個連接埠分別用於獨立的專用 Roce 儲存 VLAN 、以連線至 AFF A800 儲存系統、這些連接埠支援使用 NFS v3 、 NFSv4.x 搭配 pNFS 和 NFS over RDMA 的高效能儲存存取。

除了運算互連和高速乙太網路之外、所有實體裝置也會連線至一或多個 SN2201 乙太網路交換器、以進行頻外管理。  如需 DGX A100 系統連線的詳細資訊、請參閱 link:https://nvdam.widen.net/s/nfnjflmzlj/nvidia-dgx-basepod-reference-architecture["NVIDIA BasePOD 文件"]。



== ONTAP AI 搭配 DGX A100 系統

下圖顯示使用 DGX A100 系統和使用 ONTAP AI 的 HDR 運算架構時的整體解決方案拓撲。

image:oai_A100_topo.png["錯誤：缺少圖形影像"]

在此組態中、運算叢集網路使用一對 QM8700 HDR IB 交換器、這些交換器會連接在一起以獲得高可用度。每個 DGX A100 系統均使用四個單埠 ConnectX-6 卡以 200 Gbps 的速度連接至交換器、並將偶數連接埠連接至一台交換器、而奇數連接埠則連接至另一台交換器。

對於儲存系統存取、頻內管理和用戶端存取、會使用一對 SN4600 乙太網路交換器。交換器是透過交換器間的連結連接、並設定多個 VLAN 來隔離各種流量類型。對於較大型的部署、乙太網路可擴充至葉脊組態、視需要新增額外的交換器配對以供脊椎和其他葉片使用。每個 DGX A100 系統均配備兩個雙埠 ConnectX-6 卡、用於乙太網路和儲存流量、而此解決方案則有四個連接埠、連接至以 200 Gbps 速度連接至 SN4600 乙太網路交換器。每個卡的一個連接埠都設定為 LACP MLAG 連結、每個交換器連接一個連接埠、而用於頻內管理、用戶端存取和使用者層級儲存存取的 VLAN 則裝載在此連結上。每個卡上的另一個連接埠分別用於獨立的專用 Roce 儲存 VLAN 、以連線至 AFF A800 儲存系統、這些連接埠支援使用 NFS v3 、 NFSv4.x 搭配 pNFS 和 NFS over RDMA 的高效能儲存存取。

除了運算互連和高速乙太網路之外、所有實體裝置也會連線至一或多個 SN2201 乙太網路交換器、以進行頻外管理。  如需 DGX A100 系統連線的詳細資訊、請參閱 link:https://nvdam.widen.net/s/nfnjflmzlj/nvidia-dgx-basepod-reference-architecture["NVIDIA BasePOD 文件"]。



== 管理層伺服器

此參考架構也包含五部以 CPU 為基礎的伺服器、供管理層使用。其中兩個系統是作為 Base Command Manager 的主要節點、用於叢集部署和管理。其餘三個系統則用於提供額外的叢集服務、例如 Kubernetes 主節點或登入節點、以便使用 Slurm 進行工作排程。使用 Kubernetes 的部署可運用 NetApp Astra Trident CSI 驅動程式、為 AFF A800 儲存系統上的管理和 AI 工作負載提供自動化資源配置和資料服務、並持續儲存。

每部伺服器都會實體連接至 IB 交換器和乙太網路交換器、以啟用叢集部署和管理、並透過管理 SVM 將 NFS 裝載至儲存系統、以儲存叢集管理產出工件、如前所述。

link:aipod_nv_storage.html["下一步：採用 NVIDIA DGX 系統的 NetApp AI Pod - 儲存系統設計與規模調整指南。"]
