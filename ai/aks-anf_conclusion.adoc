---
sidebar: sidebar 
permalink: ai/aks-anf_conclusion.html 
keywords: 'Azure NetApp Files, RAPIDS AI, click-though rate (CTR) prediction, Machine Learning, Retail, E-commerce, Azure, Jupyter Notebook, Cloud computing, Digital marketing, Kubernetes' 
summary: 利用Docker和Kubernetes等協調工具、加速並簡化大型ML處理與訓練的部署。Azure NetApp Files透過統一化端點對端點資料傳輸途徑、此解決方案可降低許多進階運算工作負載固有的延遲與複雜度、有效地彌補開發與營運之間的落差。 
---
= 結論
:hardbreaks:
:allow-uri-read: 
:nofooter: 
:icons: font
:linkattrs: 
:imagesdir: ./../media/


link:aks-anf_dataset_and_model_versioning_using_netapp_dataops_toolkit.html["上一篇：使用NetApp DataOps Toolkit的資料集與模型版本管理。"]

藉由整合Docker和Kubernetes等協調工具、可加速並簡化大規模ML處理與訓練的部署。Azure NetApp Files透過統一化端點對端點資料傳輸途徑、此解決方案可降低許多進階運算工作負載固有的延遲與複雜度、有效地彌補開發與營運之間的落差。資料科學家可以在大型資料集上執行查詢、並在訓練階段與其他使用者安全地共用資料和演算法模型。

在建置自己的AI / ML管道時、設定架構中元件的整合、管理、安全性及存取能力、是一項艱鉅的任務。讓開發人員存取及控制其環境是另一組挑戰。

透過在雲端建置端點對端點分散式訓練模式和資料傳輸途徑、相較於未採用GPU加速資料處理和運算架構的傳統開放原始碼方法、我們在工作流程完成時間總計方面、表現出兩大進步。

NetApp、Microsoft、開放原始碼協調架構和NVIDIA的結合、將最新的技術整合為託管服務、提供絕佳的靈活度、可加速技術採用、並縮短新的AI/ML應用程式的上市時間。這些進階服務是在雲端原生環境中提供、可輕鬆移轉至內部部署和混合式部署架構。

link:aks-anf_where_to_find_additional_information.html["下一步：何處可找到其他資訊。"]
